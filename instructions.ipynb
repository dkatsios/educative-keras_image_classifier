{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning: Image Classification Using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 0: Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, you'll learn how to train a deep neural Network on image data. You will create a classification model that will be able to classify images into three different categories based on the image topic:\n",
    "\n",
    "- City landscape\n",
    "- Mountain landscape\n",
    "- Beach landscape\n",
    "\n",
    "The image data, 600 images in total, has been collected from pixabay. You will start by investigating the data, the directories structure, the visualization, etc. Then you will create the dataset/loaders, for the training process. After that, you will select an appropriate model for the task together with the loss function, metrics, and optimizer. You'll use keras to train the model, see how to evaluate the results, and finally, use the trained model to infer on new images.\n",
    "\n",
    "For the purpose of this project, a Jupyter Notebook will be used. Open the `/usercode/project.ipynb` file and write one piece of code for each task in one cell.\n",
    "\n",
    "Let's start!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Import Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s start by importing the necessary packages for this project. You will need:\n",
    "\n",
    "- `os` and `glob` for getting the data paths\n",
    "- `random` for random data sampling\n",
    "- `matplotlib.pyplot` for visualization\n",
    "- `tensorflow` for specific tensor operations\n",
    "- `keras` from `tensorflow` for the Deep Learning part\n",
    "- `keras_cv` for the model\n",
    "\n",
    "If you’re unsure how to do this, click the “Show Hint” button.\n",
    "\n",
    "To import packages:\n",
    "\n",
    "- Use the `import` statement\n",
    "  ```python\n",
    "  import <package_name>\n",
    "  ```\n",
    "\n",
    "- Use the following template to import module from a package.\n",
    "  ```python\n",
    "  from <package_name> import <module_name>\n",
    "  ```\n",
    "\n",
    "If you're stuck, click the \"Show Solution\" button.\n",
    "\n",
    "Use the following code to complete this task:\n",
    "```python\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_cv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Explore Directories Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images data is located under `/usercode/data/images/` directory.\n",
    "\n",
    "1. The following sub-directories are of major concern for this project:\n",
    "2. `/usercode/data/images/beach`: This folder contains images of beach landscapes.\n",
    "3. `/usercode/data/images/city`: This folder contains images of city landscapes.\n",
    "4. `/usercode/data/images/mountain`: This folder contains multiple images of mountain landscapes.\n",
    "\n",
    "Each of these subdirectories contains 200 images.\n",
    "\n",
    "Create a dictionary where the keys will be the names of the sub-directories of the above directory and the values will be a list with the file paths under each sub-directory. This way you will have a better idea of the structure of the dataset and the directories.\n",
    "\n",
    "After you create the dictionary print the directory name, the number of files inside each directory, and the first five (5) file paths of each sub-directory.\n",
    "\n",
    "If you're unsure how to do this, click the \"Show Hint\" button.\n",
    "\n",
    "- Use the `os.path.listdir()` function to get the names of the sub-directories, as follows:\n",
    "  ```python\n",
    "  os.path.listdir(\"</some/path>\")\n",
    "  ```\n",
    "\n",
    "- Use the `glob.glob()` function for getting the list of the file paths of one directory, as follows:\n",
    "  ```python\n",
    "  glob.glob(\"</some/path/*>\")\n",
    "  ```\n",
    "\n",
    "If you're stuck, click the \"Show Solution\" button.\n",
    "\n",
    "Use the following code to complete this task:\n",
    "```python\n",
    "IMAGES_DIR = \"/usercode/data/images/\"\n",
    "\n",
    "dir_names = os.listdir(IMAGES_DIR)\n",
    "img_paths_dict = dict()\n",
    "for dir_name in dir_names:\n",
    "    img_paths_dict[dir_name] = glob.glob(f\"{IMAGES_DIR}{dir_name}/*\")\n",
    "\n",
    "for dir_name, file_paths in img_paths_dict.items():\n",
    "    print(dir_name, len(file_paths))\n",
    "    for file_path in file_paths[:5]:\n",
    "        print(file_path)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Visualize Image Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, let’s plot some images to get an idea of what they look like.\n",
    "\n",
    "For this, use the `pyplot` module from the `matplotlib` library to show the first 5 images of each directory.\n",
    "\n",
    "If you're unsure how to do this, click the \"Show Hint\" button.\n",
    "\n",
    "- Use `plt.imread()` to read an image\n",
    "- Use `plt.imshow()` to show the image\n",
    "\n",
    "If you're stuck, click the \"Show Solution\" button.\n",
    "\n",
    "Use the following code to complete this task:\n",
    "```python\n",
    "for dir_name, file_paths in img_paths_dict.items():\n",
    "    print(dir_name)\n",
    "    for file_path in file_paths[:5]:\n",
    "        image = plt.imread(file_path)\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Create a Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While training a deep learning model, it is difficult to hold all the data in the memory. For that, you use data loaders that read the data from files and serve them to the model. Keras/TF comes with many data-loading functions that cover a variety of cases. Since you have an image classification task with the images of each class in separate directories you can use the `image_dataset_from_directory()` function.\n",
    "\n",
    "In this task, create a dataset using the `image_dataset_from_directory()` function with all the available images.\n",
    "\n",
    "For image size use 128x128, this will be the size you will also use for training. The reason is that the training will go faster if the size of the images is smaller, especially if it runs on CPU instead of GPU. However, keep in mind that sometimes dropping the resolution leads to worse results.\n",
    "\n",
    "The `label_mode` should be <\"categorical\"> since you want the output to be a one-hot vector, meaning 1 for the correct class and 0 for all the other classes.\n",
    "\n",
    "If you're unsure how to do this, click the \"Show Hint\" button.\n",
    "\n",
    "- Here is the template of `image_dataset_from_directory()` function from the Keras documentation:\n",
    "\n",
    "  ```python\n",
    "  keras.utils.image_dataset_from_directory(\n",
    "      directory,\n",
    "      labels=\"inferred\",\n",
    "      label_mode=\"int\",\n",
    "      class_names=None,\n",
    "      color_mode=\"rgb\",\n",
    "      batch_size=32,\n",
    "      image_size=(256, 256),\n",
    "      shuffle=True,\n",
    "      seed=None,\n",
    "      validation_split=None,\n",
    "      subset=None,\n",
    "      interpolation=\"bilinear\",\n",
    "      follow_links=False,\n",
    "      crop_to_aspect_ratio=False,\n",
    "      data_format=None,\n",
    "  )\n",
    "  ```\n",
    "- Use `dataset.class_names` to get access to the names of the classes.\n",
    "- Use `tf.math.argmax()` to get the index of the largest element of a tensor.\n",
    "- Use the `numpy()` method on a tensor to make it into a NumPy array. Also, cast it to `uint8` type to plot it.\n",
    "\n",
    "If you're stuck, click the \"Show Solution\" button.\n",
    "\n",
    "Use the following code to complete this task:\n",
    "```python\n",
    "dataset = keras.utils.image_dataset_from_directory(\n",
    "    IMAGES_DIR, image_size=(128, 128), label_mode=\"categorical\"\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Inspect Dataset Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `dataset` object you created in **Task 4** will iterate over the image paths, load them as tensors, and return them in batches. Let's inspect the type and dimensionality of the objects returned objects and visualize some of these images.\n",
    "\n",
    "Write the code to:\n",
    "- Load one batch of images-labels pairs.\n",
    "- Print\n",
    "  1. The type of the returned object.\n",
    "  2. The dtype of the tensor.\n",
    "  3. The dimensions/shape of it.\n",
    "- Plot the first image of the batch.\n",
    "\n",
    "If you're unsure how to do this, click the \"Show Hint\" button.\n",
    "\n",
    "- To get one batch (images, labels) from the dataset, create an iterator `iter()` from the dataset, and call `next()` on it.\n",
    "- To plot the image correctly with `matplotlib.pyplot`, change the type of the image from `float32` to `uint8`.\n",
    "\n",
    "If you're stuck, click the \"Show Solution\" button.\n",
    "\n",
    "Use the following code to complete this task:\n",
    "```python\n",
    "images, labels = next(iter(dataset))\n",
    "\n",
    "print(f\"type: {type(images)}\")\n",
    "print(f\"dtype: {images.dtype}\")\n",
    "print(f\"shape: {images.shape}\")\n",
    "\n",
    "print(dataset.class_names[tf.math.argmax(labels[0])])\n",
    "plt.imshow(images[0].numpy().astype(\"uint8\"))\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Create Train and Validation Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is usually split into 3 subsets during model training.\n",
    "- Train data: these are the images that you will use to train our model. You will iterate over them multiple times (epochs) and provide the ground truth (correct class for each image) so that the model \"learns\" to predict the correct output itself.\n",
    "- Validation data: these are images that you don't feed to the model during training. Instead, after each epoch you get the model predictions on these images and compare them with the ground truth. This way you can tell how our model performs on new images.\n",
    "- Test data: these are the images you use at the end of the training process to evaluate the final model performance. \n",
    "\n",
    "In our case, you will use the validation data as test data for simplicity.\n",
    "\n",
    "Create the two datasets with a split ratio of:\n",
    "- Train dataset: 80%.\n",
    "- Validation dataset: 20%.\n",
    "\n",
    "Use the same parameters as for the `dataset` from the previous task:\n",
    "- Image size 128x128.\n",
    "- Label mode \"categorical\".\n",
    "\n",
    "If you're unsure how to do this, click the \"Show Hint\" button.\n",
    "\n",
    "- To create a validation split use the `image_dataset_from_directory()` function. This function takes the following arguments:\n",
    "  - `validation_split`: Optional float between 0 and 1, fraction of data to reserve for validation.\n",
    "  - `subset`: Subset of the data to return. One of \"training\", \"validation\", or \"both\". Only used if validation_split is set. When subset=\"both\", the utility returns a tuple of two datasets (the training and validation datasets respectively).\n",
    "\n",
    "If you're stuck, click the \"Show Solution\" button.\n",
    "\n",
    "Use the following code to complete this task:\n",
    "```python\n",
    "train_ds = keras.utils.image_dataset_from_directory(\n",
    "    IMAGES_DIR,\n",
    "    image_size=(128, 128),\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    label_mode=\"categorical\",\n",
    "    seed=0,\n",
    ")\n",
    "valid_ds = keras.utils.image_dataset_from_directory(\n",
    "    IMAGES_DIR,\n",
    "    image_size=(128, 128),\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    label_mode=\"categorical\",\n",
    "    seed=0,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7: Create the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create the model. There are two steps in this task. \n",
    "\n",
    "The first step is to create the backbone of the model. This is the big part that is pre-trained on a large amount of data and contains the general knowledge of the model. Instead of starting from scratch, in most cases, it is a good idea to use an already trained backbone and then fine-tune it on your own data.\n",
    "\n",
    "One of the best image-related models for general tasks is the EfficientNet family. For this task, you will use the smaller model named EfficientNet B0. If this is not good enough for other tasks, you can always use a bigger model, like EfficientNet B4, or even the biggest one: EfficientNet B7!\n",
    "\n",
    "The second step is to create our classifier. You'll use the backbone and define an ImageClassifier object. This will be the model that you will train on the data and the use for inference. Since there are three classes (city, mountain, beach), the model output will be three numbers that sum up to 1. The class with the highest number will be the one that the model predicted for the given image.\n",
    "\n",
    "So, in conclusion, for this task:\n",
    "\n",
    "1. For the first step, you will make use of the `keras_cv.models.EfficientNetV2Backbone` class and call the `from_preset()` method with `efficientnetv2_b0_imagenet` as the backbone name.\n",
    "2. For the second step, you will use the `keras_cv.models.ImageClassifier` class and create an instance using the backbone of the first step. You will also define the number of classes (three in this case) and the activation. \n",
    "\n",
    ">**Note:** For classification tasks, where each sample can belong to one and only one class, softmax is a good activation choice.\n",
    "\n",
    "If you're unsure how to do this, click the \"Show Hint\" button.\n",
    "\n",
    "- Use the `keras_cv.models.EfficientNetV2Backbone.from_preset()` to get the backbone.\n",
    "- Use the `keras_cv.models.ImageClassifier()` to get the final model.\n",
    "\n",
    "If you're stuck, click the \"Show Solution\" button.\n",
    "\n",
    "Use the following code to complete this task:\n",
    "```python\n",
    "backbone = keras_cv.models.EfficientNetV2Backbone.from_preset(\"efficientnetv2_b0_imagenet\")\n",
    "\n",
    "model = keras_cv.models.ImageClassifier(\n",
    "    backbone=backbone,\n",
    "    num_classes=3,\n",
    "    activation=\"softmax\",\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8: Define Loss and Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function is the function that is sought to be minimized during training. It usually depicts how far are the predictions from the ground truth (correct classes). The loss function choice is very important since it is the one that drives the process of training. In this project, there are more than two exclusive classes. For this, a good choice is the `CategoricalCrossentropy`.\n",
    "\n",
    "The metrics are functions that are used as indicators of the model’s performance. They don’t affect the training process themselves, but they give an idea of how well the model will perform. For this project, a simple yet good metric is `CategoricalAccuracy`, which is the ratio of correct predictions.\n",
    "\n",
    "> **Note:** The metric result is usually a number that can be interpreted in a meaningful way (e.g. % of success, % of failed cases, number of false positives, etc.). In contrast, the loss function result is not always easy to interpret. Another difference between the loss function and the metrics functions is that the first has to be differentiable so that it can be backpropagated and model weights be updated. The later can be any function, as long as it can be represented in the framework.\n",
    "\n",
    "In this task, you’ll define the loss function and an evaluation metric.\n",
    "\n",
    "If you're unsure how to do this, click the \"Show Hint\" button.\n",
    "\n",
    "- Use the `CategoricalCrossentropy()` method from `keras.losses` module to compute catagorical crossentropy.\n",
    "- Use the `CategoricalAccuracy()` method from `keras.metrics` module to calculate prediction accuracy.\n",
    "\n",
    "If you're stuck, click the \"Show Solution\" button.\n",
    "\n",
    "Use the following code to complete this task:\n",
    "```python\n",
    "loss = keras.losses.CategoricalCrossentropy()\n",
    "metric = keras.metrics.CategoricalAccuracy()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9: Compile the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this project is using keras as the DL framework, keras provides a simple way to make use of the loss function and the metrics. \n",
    "In this task, you’ll compile the model using the loss and metric functions. For this, you’ll call the `compile()` method on the model and pass the defined `loss` and `metric` from **Task 8**, and keras will take care of everything.\n",
    "\n",
    "\n",
    "If you're unsure how to do this, click the \"Show Hint\" button.\n",
    "\n",
    "This is the template for the compile method from the keras documentation\n",
    "\n",
    "```python\n",
    "Model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=None,\n",
    "    loss_weights=None,\n",
    "    metrics=None,\n",
    "    weighted_metrics=None,\n",
    "    run_eagerly=False,\n",
    "    steps_per_execution=1,\n",
    "    jit_compile=\"auto\",\n",
    "    auto_scale_loss=True,\n",
    ")\n",
    "```\n",
    "\n",
    "If you're stuck, click the \"Show Solution\" button.\n",
    "\n",
    "Use the following code to complete this task:\n",
    "```python\n",
    "model.compile(loss=loss, metrics=metric)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 10: Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to train the model. Again, keras framework offers a very convenient way to train a model given our datasets which is the `fit()` method.\n",
    "\n",
    "Train the model for 2 epochs. After each epoch:\n",
    "- The model will be called on our validation data and the validation metric will be calculated.\n",
    "- This number is the expected accuracy of the model on new (unseen) data.\n",
    "\n",
    ">**Note:** One epoch is one pass through all the train data\n",
    "\n",
    "If you’re unsure how to do this, click the “Show Hint” button.\n",
    "\n",
    "This is the template of the `fit()` method from keras documentation\n",
    "```python\n",
    "Model.fit(\n",
    "    x=None,\n",
    "    y=None,\n",
    "    batch_size=None,\n",
    "    epochs=1,\n",
    "    verbose=\"auto\",\n",
    "    callbacks=None,\n",
    "    validation_split=0.0,\n",
    "    validation_data=None,\n",
    "    shuffle=True,\n",
    "    class_weight=None,\n",
    "    sample_weight=None,\n",
    "    initial_epoch=0,\n",
    "    steps_per_epoch=None,\n",
    "    validation_steps=None,\n",
    "    validation_batch_size=None,\n",
    "    validation_freq=1,\n",
    ")\n",
    "```\n",
    "\n",
    "If you’re stuck, click the “Show Solution” button.\n",
    "\n",
    "\n",
    "Use the following code to complete this task:\n",
    "\n",
    "```python\n",
    "model.fit(train_ds, validation_data=valid_ds, epochs=2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 11: Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the model is trained. Let's see what is the model performance. Use the `evaluate()` method to get the loss and the accuracy of the model on the validation data. print the two numbers.\n",
    "\n",
    "\n",
    "If you’re unsure how to do this, click the “Show Hint” button.\n",
    "\n",
    "\n",
    "This is the evaluate() method template from the keras configuration.\n",
    "\n",
    "```python\n",
    "Model.evaluate(\n",
    "    x=None,\n",
    "    y=None,\n",
    "    batch_size=None,\n",
    "    verbose=\"auto\",\n",
    "    sample_weight=None,\n",
    "    steps=None,\n",
    "    callbacks=None,\n",
    "    return_dict=False,\n",
    "    **kwargs\n",
    ")\n",
    "```\n",
    "\n",
    "If you’re stuck, click the “Show Solution” button.\n",
    "\n",
    "\n",
    "Use the following code to complete this task:\n",
    "```python\n",
    "loss, acc = model.evaluate(valid_ds, verbose=False)\n",
    "print(f\"{loss=:.3}, {acc=:.3}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 12: Use Model on an Unseen Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the last task you will use the trained model to get the prediction on a new photo.\n",
    "- Pick a random photo from any of the directories.\n",
    "- Use the `predict()` model method to get the prediction for this photo.\n",
    "- Get the name of the class from the model prediction\n",
    "- Print the label and plot the image to confirm that it is correct.\n",
    "\n",
    "If you’re unsure how to do this, click the “Show Hint” button.\n",
    "\n",
    "\n",
    "This is the `predict()` template from the keras documentation\n",
    "\n",
    "```python\n",
    "Model.predict(x, batch_size=None, verbose=\"auto\", steps=None, callbacks=None)\n",
    "```\n",
    "\n",
    "\n",
    "If you’re stuck, click the “Show Solution” button.\n",
    "\n",
    "Use the following code to complete this task:\n",
    "```python\n",
    "image_paths = glob.glob(f\"{IMAGES_DIR}/*/*\")\n",
    "image = plt.imread(random.choice(image_paths))\n",
    "\n",
    "predictions = model.predict(image[None, ...], verbose=False)[0]\n",
    "pred_cls = valid_ds.class_names[predictions.argmax()]\n",
    "\n",
    "print(pred_cls)\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 13: Congratulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! In this project you successfully trained a classification model on image data and used it to predict the class of previously unseen images. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
