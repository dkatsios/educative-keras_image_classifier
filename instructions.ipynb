{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning: Image Classification Using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 0: Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, you'll learn how to train a deep neural Network on image data. You will create a classification model that will be able to classify images into three different categories based on the image topic:\n",
    "\n",
    "- City landscape\n",
    "- Mountain landscape\n",
    "- Beach landscape\n",
    "\n",
    "The image data, 600 images in total, has been collected from pixabay. You will start by investigating the data, the directories structure, the visualization, etc. Then you will create the dataset/loaders, for the training process. After that, you will select an appropriate model for the task together with the loss function, metrics, and optimizer. You'll use keras to train the model, see how to evaluate the results, and finally, use the trained model to infer on new images.\n",
    "\n",
    "For the purpose of this project, a Jupyter Notebook will be used. Open the `/usercode/project.ipynb` file and write one piece of code for each task in one cell.\n",
    "\n",
    "Let's start!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Import Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s start by importing the necessary packages for this project. You will need:\n",
    "\n",
    "- `os` and `glob` for getting the data paths\n",
    "- `random` for random data sampling\n",
    "- `matplotlib.pyplot` for visualization\n",
    "- `tensorflow` for specific tensor operations\n",
    "- `keras` from `tensorflow` for the Deep Learning part\n",
    "- `keras_cv` for the model\n",
    "\n",
    "If you’re unsure how to do this, click the “Show Hint” button.\n",
    "\n",
    "To import packages:\n",
    "\n",
    "- Use the `import` statement\n",
    "  ```python\n",
    "  import <package_name>\n",
    "  ```\n",
    "\n",
    "- Use the following template to import module from a package.\n",
    "  ```python\n",
    "  from <package_name> import <module_name>\n",
    "  ```\n",
    "\n",
    "If you're stuck, click the \"Show Solution\" button.\n",
    "\n",
    "Use the following code to complete this task:\n",
    "```python\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_cv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Explore Directories Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image data are located under `/usercode/data/images/` directory.\n",
    "\n",
    "1. The following sub-directories are of major concern for this project:\n",
    "2. `/usercode/data/images/beach`: This folder contains images of beach landscapes.\n",
    "3. `/usercode/data/images/city`: This folder contains images of city landscapes.\n",
    "4. `/usercode/data/images/mountain`: This folder contains multiple images of mountain landscapes.\n",
    "\n",
    "Each of these subdirectories contains 200 images.\n",
    "\n",
    "Create a dictionary where the keys will be the names of the sub-directories of the above directory and the values will be a list with the file paths under each sub-directory. This way you will have a better idea of the structure of the dataset and the directories.\n",
    "\n",
    "After you create the dictionary print the directory name, the number of files inside each directory, and the first five (5) file paths of each sub-directory.\n",
    "\n",
    "If you're unsure how to do this, click the \"Show Hint\" button.\n",
    "\n",
    "- Use the `os.path.listdir()` function to get the names of the sub-directories, as follows:\n",
    "  ```python\n",
    "  os.path.listdir(\"</some/path>\")\n",
    "  ```\n",
    "\n",
    "- Use the `glob.glob()` function for getting the list of the file paths of one directory, as follows:\n",
    "  ```python\n",
    "  glob.glob(\"</some/path/*>\")\n",
    "  ```\n",
    "\n",
    "If you're stuck, click the \"Show Solution\" button.\n",
    "\n",
    "Use the following code to complete this task:\n",
    "```python\n",
    "IMAGES_DIR = \"/usercode/data/images/\"\n",
    "\n",
    "dir_names = os.listdir(IMAGES_DIR)\n",
    "img_paths_dict = dict()\n",
    "for dir_name in dir_names:\n",
    "    img_paths_dict[dir_name] = glob.glob(f\"{IMAGES_DIR}{dir_name}/*\")\n",
    "\n",
    "for dir_name, file_paths in img_paths_dict.items():\n",
    "    print(dir_name, len(file_paths))\n",
    "    for file_path in file_paths[:5]:\n",
    "        print(file_path)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Visualize Image Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, let’s plot some images to get an idea of what they look like.\n",
    "\n",
    "For this, use the `pyplot` module from the `matplotlib` library to show the first 5 images of each directory.\n",
    "\n",
    "If you're unsure how to do this, click the \"Show Hint\" button.\n",
    "\n",
    "- Use `plt.imread()` to read an image\n",
    "- Use `plt.imshow()` to show the image\n",
    "\n",
    "If you're stuck, click the \"Show Solution\" button.\n",
    "\n",
    "Use the following code to complete this task:\n",
    "```python\n",
    "for dir_name, file_paths in img_paths_dict.items():\n",
    "    print(dir_name)\n",
    "    for file_path in file_paths[:5]:\n",
    "        image = plt.imread(file_path)\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Create a Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While training a deep learning model, it is difficult to hold all the data in the memory. For that, you use data loaders that read the data from files and serve them to the model. Keras/TF comes with many data-loading functions that cover a variety of cases. Since you have an image classification task with the images of each class in separate directories you can use the `image_dataset_from_directory()` function.\n",
    "\n",
    "In this task, create a dataset using the `image_dataset_from_directory()` function with all the available images.\n",
    "\n",
    "For image size use 128x128, this will be the size we will also use for training. The reason is that the training will go faster if the size of the images is smaller, especially if it runs on CPU instead of GPU. However, keep in mind that sometimes dropping the resolution leads to worse results.\n",
    "\n",
    "The `label_mode` should be <\"categorical\"> since we want the output to be a one-hot vector, meaning 1 for the correct class and 0 for all the other classes.\n",
    "\n",
    "If you're unsure how to do this, click the \"Show Hint\" button.\n",
    "\n",
    "- Here is the template of `image_dataset_from_directory()` function from the Keras documentation:\n",
    "\n",
    "  ```python\n",
    "  keras.utils.image_dataset_from_directory(\n",
    "      directory,\n",
    "      labels=\"inferred\",\n",
    "      label_mode=\"int\",\n",
    "      class_names=None,\n",
    "      color_mode=\"rgb\",\n",
    "      batch_size=32,\n",
    "      image_size=(256, 256),\n",
    "      shuffle=True,\n",
    "      seed=None,\n",
    "      validation_split=None,\n",
    "      subset=None,\n",
    "      interpolation=\"bilinear\",\n",
    "      follow_links=False,\n",
    "      crop_to_aspect_ratio=False,\n",
    "      data_format=None,\n",
    "  )\n",
    "  ```\n",
    "- Use `dataset.class_names` to get access to the names of the classes.\n",
    "- Use `tf.math.argmax()` to get the index of the largest element of a tensor.\n",
    "- Use the `numpy()` method on a tensor to make it into a NumPy array. Also, cast it to `uint8` type to plot it.\n",
    "\n",
    "If you're stuck, click the \"Show Solution\" button.\n",
    "\n",
    "Use the following code to complete this task:\n",
    "```python\n",
    "dataset = keras.utils.image_dataset_from_directory(\n",
    "    IMAGES_DIR, image_size=(128, 128), label_mode=\"categorical\"\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Inspect Dataset Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `dataset` object you created in **Task 4** will iterate over the image paths, load them as tensors, and return them in batches. Let's inspect the type and dimensionality of the objects returned objects and visualize some of these images.\n",
    "\n",
    "Write the code to:\n",
    "- Load one batch of images-labels pairs.\n",
    "- Print\n",
    "  - the type of the returned object\n",
    "  - the dtype of the tensor\n",
    "  - the dimensions/shape of it\n",
    "- Plot the first image of the batch.\n",
    "\n",
    "If you're unsure how to do this, click the \"Show Hint\" button.\n",
    "\n",
    "- To get one batch (images, labels) from the dataset, create an iterator `iter()` from the dataset, and call `next()` on it.\n",
    "- To plot the image correctly, change the type of the image from `float32` to `uint8`.\n",
    "\n",
    "If you're stuck, click the \"Show Solution\" button.\n",
    "\n",
    "Use the following code to complete this task:\n",
    "```python\n",
    "images, labels = next(iter(dataset))\n",
    "\n",
    "print(f\"type: {type(images)}\")\n",
    "print(f\"dtype: {images.dtype}\")\n",
    "print(f\"shape: {images.shape}\")\n",
    "\n",
    "print(dataset.class_names[tf.math.argmax(labels[0])])\n",
    "plt.imshow(images[0].numpy().astype(\"uint8\"))\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Create Train and Validation Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During model training, you usually split our data into 3 subsets:\n",
    "- train data: these are the images that you will use to train our model. You will iterate over them multiple times (epochs) and provide the ground truth (correct class for each image) so that the model \"learns\" to predict the correct output itself.\n",
    "- validation data: these are images that you don't feed to the model during training. Instead, after each epoch you get the model predictions on these images and compare them with the ground truth. This way you can tell how our model performs on new images.\n",
    "- test data: these are the images you use at the end of the training process to evaluate the final model performance. \n",
    "\n",
    "In our case, you will use the validation data as test data for simplicity.\n",
    "\n",
    "Create the two datasets with a split ratio of:\n",
    "- Train dataset: 80%.\n",
    "- Validation dataset: 20%.\n",
    "\n",
    "Use the same parameters as for the `dataset` from the previous task:\n",
    "- Image size 128x128.\n",
    "- Label mode \"categorical\".\n",
    "\n",
    "If you're unsure how to do this, click the \"Show Hint\" button.\n",
    "\n",
    "To create a validation split use the `image_dataset_from_directory()` function. This function takes the following arguments:\n",
    "- `validation_split`: Optional float between 0 and 1, fraction of data to reserve for validation.\n",
    "- `subset`: Subset of the data to return. One of \"training\", \"validation\", or \"both\". Only used if validation_split is set. When subset=\"both\", the utility returns a tuple of two datasets (the training and validation datasets respectively).\n",
    "\n",
    "If you're stuck, click the \"Show Solution\" button.\n",
    "\n",
    "Use the following code to complete this task:\n",
    "```python\n",
    "train_ds = keras.utils.image_dataset_from_directory(\n",
    "    IMAGES_DIR,\n",
    "    image_size=(128, 128),\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    label_mode=\"categorical\",\n",
    "    seed=0,\n",
    ")\n",
    "valid_ds = keras.utils.image_dataset_from_directory(\n",
    "    IMAGES_DIR,\n",
    "    image_size=(128, 128),\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    label_mode=\"categorical\",\n",
    "    seed=0,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7: Create the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create our model. There are two steps in this task. \n",
    "\n",
    "The first step is to create the backbone of the model. This is the big part that is pre-trained on a large amount of data and contains the general knowledge of the model. Instead of starting from scratch, in most cases, it is a good idea to use an already trained backbone and then fine-tune it on our own data.\n",
    "\n",
    "One of the best image-related models for general tasks is the EfficientNet family. For our task, we will use the smaller model named EfficientNet B0. If this is not good enough for other tasks, you can always use a bigger model, like EfficientNet B4, or even the biggest one: EfficientNet B7!\n",
    "\n",
    "The second step is to create our classifier. You'll use the backbone and define an ImageClassifier object. This will be the model that we will train on our data and the use for inference. Since we have 3 classes (city, mountain, beach), the model output will be 3 numbers that sum up to 1. The class with the highest number will be the one that the model predicted for the given image.\n",
    "\n",
    "So, in conclusion, for this task:\n",
    "\n",
    "- For the first step, you will make use of the `keras_cv.models.EfficientNetV2Backbone` class and call the `from_preset()` method with \"efficientnetv2_b0_imagenet\" as the backbone name.\n",
    "- For the second step, you will use the `keras_cv.models.ImageClassifier` class and create an instance using the backbone of the first step. You will also define the number of classes (3 in our case) and the activation. For classification tasks, where each sample can belong to one and only one class, `softmax` is a good activation choice. For labeling tasks, where each sample can have more than one label, `sigmoid` is a good choice for activation function.\n",
    "\n",
    "If you're unsure how to do this, click the \"Show Hint\" button.\n",
    "\n",
    "Use:\n",
    "- `keras_cv.models.EfficientNetV2Backbone.from_preset()` to get the backbone\n",
    "- `keras_cv.models.ImageClassifier()` to get the final model\n",
    "\n",
    "If you're stuck, click the \"Show Solution\" button.\n",
    "\n",
    "Use the following code to complete this task:\n",
    "```python\n",
    "backbone = keras_cv.models.EfficientNetV2Backbone.from_preset(\"efficientnetv2_b0_imagenet\")\n",
    "\n",
    "model = keras_cv.models.ImageClassifier(\n",
    "    backbone=backbone,\n",
    "    num_classes=3,\n",
    "    activation=\"softmax\",\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8: Define Loss and Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss\n",
    "\n",
    "The loss function is the function that we try to minimize during training. It usually depicts how far are our predictions from the ground truth (correct classes). The loss function choice is very important since it is the one that drives the process of training.\n",
    "\n",
    "In our case, we have more than two, exclusive classes. For this, a good choice is the `CategoricalCrossentropy`.\n",
    "\n",
    "### Metrics\n",
    "\n",
    "The metrics are functions that are used as indicators of the performance of the model. They don't affect the training process itself, but they give an idea of how well the model will perform. The metric result is usually a number that we can interpret in a meaningful way (e.g. % of success, % of failed cases, number of False Positives, etc.). In contrast, the loss function result is not always easy to interpret.\n",
    "\n",
    "For our task, a simple yet good metric is `CategoricalAccuracy`, which is the ratio of correct predictions.\n",
    "\n",
    "Another difference between the loss function and the metrics functions is that the first has to be differentiable so that we can backpropagate and update the model weights. The laters can be any function we want, as long as it can be represented in our framework.\n",
    "\n",
    "If you're unsure how to do this, click the \"Show Hint\" button.\n",
    "\n",
    "- Use `CategoricalCrossentropy` from `keras.losses` module.\n",
    "- Use `CategoricalAccuracy` from `keras.metrics` module.\n",
    "\n",
    "If you're stuck, click the \"Show Solution\" button.\n",
    "\n",
    "Use the following code to complete this task:\n",
    "```python\n",
    "loss = keras.losses.CategoricalCrossentropy()\n",
    "metric = keras.metrics.CategoricalAccuracy()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9: Compile the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we use keras as our DL framework, there is a simple way to make use of our loss function and the metrics. You can call the `compile()` method on the model and pass the defined `loss` and `metric` from **Task 8**, and keras will take care of everything. Otherwise, we would have to manually call the loss/metric functions on the model outputs and the labels.\n",
    "\n",
    "Compile the model using the loss and metric functions.\n",
    "\n",
    "If you're unsure how to do this, click the \"Show Hint\" button.\n",
    "\n",
    "This is the template for the compile method from the keras documentation\n",
    "\n",
    "```python\n",
    "Model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=None,\n",
    "    loss_weights=None,\n",
    "    metrics=None,\n",
    "    weighted_metrics=None,\n",
    "    run_eagerly=False,\n",
    "    steps_per_execution=1,\n",
    "    jit_compile=\"auto\",\n",
    "    auto_scale_loss=True,\n",
    ")\n",
    "```\n",
    "\n",
    "If you're stuck, click the \"Show Solution\" button.\n",
    "\n",
    "Use the following code to complete this task:\n",
    "```python\n",
    "model.compile(loss=loss, metrics=metric)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=loss, metrics=metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 10: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_ds, validation_data=valid_ds, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 11: Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(valid_ds, verbose=False)\n",
    "print(f\"{loss=:.3}, {acc=:.3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 12: Use Model on New Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = glob.glob(f\"{IMAGES_DIR}/*/*\")\n",
    "image = plt.imread(random.choice(image_paths))\n",
    "\n",
    "predictions = model.predict(image[None, ...], verbose=False)[0]\n",
    "pred_cls = valid_ds.class_names[predictions.argmax()]\n",
    "\n",
    "print(pred_cls)\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
